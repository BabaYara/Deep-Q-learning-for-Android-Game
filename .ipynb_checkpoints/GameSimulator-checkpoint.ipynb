{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if 'session' in locals() and session is not None:\n",
    "    print('Close interactive session')\n",
    "    session.close()\n",
    "# Deep-Q learning Agent\n",
    "class DQNAgent:\n",
    "    def __init__(self):\n",
    "        self.memory = []\n",
    "        self.gamma = 0.9  # decay rate\n",
    "        self.epsilon = 1  # exploration\n",
    "        self.epsilon_decay = .995\n",
    "        self.epsilon_min = 0.1\n",
    "        self.learning_rate = 0.0001\n",
    "        self._build_model()\n",
    "    \n",
    "    def _build_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Flatten(input_shape=(1,300,300)))\n",
    "        model.add(Dense(128, activation='relu'))\n",
    "        model.add(Dense(128, activation='relu'))\n",
    "        model.add(Dense(5, activation='linear'))\n",
    "        model.compile(loss='mse',\n",
    "                      optimizer=RMSprop(lr=self.learning_rate))\n",
    "        print(\"Now we build the model\")\n",
    "        # model = Sequential()\n",
    "        # model.add(Convolution2D(32, 8, 8, subsample=(4,4),input_shape=(1,300,300), border_mode='same'))\n",
    "        # model.add(Activation('relu'))\n",
    "        # model.add(Convolution2D(64, 4, 4, subsample=(2,2), border_mode='same'))\n",
    "        # model.add(Activation('relu'))\n",
    "        # model.add(Convolution2D(64, 3, 3, subsample=(1,1), border_mode='same'))\n",
    "        # model.add(Activation('relu'))\n",
    "        # model.add(Flatten())\n",
    "        # model.add(Dense(512))\n",
    "        # model.add(Activation('linear'))\n",
    "        # model.add(Dense(5))\n",
    "\n",
    "        # adam = Adam(lr=1e-6)\n",
    "        # model.compile(loss='mse',optimizer=adam)\n",
    "        print(\"We finish building the model\")\n",
    "        self.model = model\n",
    "    \n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "    \n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return int(random.uniform(0, 3))\n",
    "        act_values = self.model.predict(state)\n",
    "        return int(np.argmax(act_values[0]))  # returns action\n",
    "    \n",
    "    def replay(self, batch_size):\n",
    "        batches = min(batch_size, len(self.memory))\n",
    "        batches = np.random.choice(len(self.memory), batches)\n",
    "        for i in batches:\n",
    "            state, action, reward, next_state, done = self.memory[i]\n",
    "            target = reward\n",
    "            if not done:\n",
    "                target = reward + self.gamma * np.argmax(self.model.predict(next_state))\n",
    "            target_f = self.model.predict(state)\n",
    "            target_f[0][action] = target\n",
    "            # print (\"started training episode\")\n",
    "            self.model.fit(state, target_f, nb_epoch=1, verbose=0)\n",
    "            # print (\"finished training episode\")\n",
    "        self.model.save_weights(\"modelSmove.h5\")\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\suhag\\AppData\\Local\\conda\\conda\\envs\\py35\\lib\\site-packages\\keras\\models.py:826: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import pyscreenshot as ImageGrab\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import keras\n",
    "import win32api, win32con\n",
    "from random import sample\n",
    "from keras import backend as K\n",
    "import random\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.layers import Dense, Flatten, Convolution2D, MaxPooling2D, Activation\n",
    "from keras.optimizers import sgd, Adam, RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import sys\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "\n",
    "orig_stdout = sys.stdout\n",
    "f = open('out.txt', 'w')\n",
    "sys.stdout = f\n",
    "\n",
    "\n",
    "x_pad = 1500\n",
    "y_pad = 50\n",
    "\n",
    "def preprocess(im1):\n",
    "    im1= im1.resize((300,300))\n",
    "    im1 = im1.convert('L')\n",
    "    print(\"[INFO] loading and preprocessing image...\")\n",
    "    image = img_to_array(im1)\n",
    "    image = image.reshape((1,) + image.shape)  # this is a Numpy array with shape (1, 3, 300, 300)\n",
    "    test_ob = ImageDataGenerator(rescale=1./255)\n",
    "    X=[]\n",
    "    for batch in test_ob.flow(image, batch_size=1):\n",
    "        X= batch\n",
    "        break\n",
    "    return X\n",
    "def checkGameOver():\n",
    "    im = screenGrab()\n",
    "    left = 0\n",
    "    top = 130\n",
    "    width = 230\n",
    "    height = 50\n",
    "    box = (left, top, left+width, top+height)\n",
    "    im2 = im.crop(box)\n",
    "    text = pytesseract.image_to_string(im2)\n",
    "    GAME_OVER = ['S','c','o','r','e',':']     \n",
    "    if any(val in text for val in GAME_OVER):\n",
    "        # print \"=====Check game over=======\\n\"\n",
    "        # print('Game over encountered')\n",
    "        # print \"===========================\\n\"\n",
    "        return True\n",
    "    else:\n",
    "        # print \"=====Check game over=======\\n\"\n",
    "        # print('Countinue playing the game')\n",
    "        # print \"===========================\\n\"\n",
    "        return False\n",
    "\n",
    "def getScore():\n",
    "    im = screenGrab()\n",
    "    left = 0\n",
    "    top = 25\n",
    "    width = 40\n",
    "    height = 40\n",
    "    box = (left, top, left+width, top+height)\n",
    "    im2 = im.crop(box)\n",
    "    text = pytesseract.image_to_string(im2)\n",
    "    # print \"=====Get score=============\\n\"\n",
    "    # print('the score is :' + text )\n",
    "    # print \"===========================\\n\"\n",
    "    try:\n",
    "        return int(text)\n",
    "    except ValueError:\n",
    "        # print 'errror encountered in reading score'\n",
    "        return -1\n",
    "\n",
    "def closeAd():\n",
    "    \"\"\"\n",
    "        still have to write code for closing the add\n",
    "    \"\"\"\n",
    "    x,y = -803, -62\n",
    "    mousePos((x, y))\n",
    "    time.sleep(.1)\n",
    "    leftClick()\n",
    "    time.sleep(.1)\n",
    "    # print \"===========================\\n\"\n",
    "    # print('add closed ')\n",
    "    # print \"===========================\\n\"\n",
    "\n",
    "def restartGame():\n",
    "    \"\"\"\n",
    "        click restart game \n",
    "    \"\"\"\n",
    "    x,y = -87, 565\n",
    "    mousePos((x, y))\n",
    "    time.sleep(.1)\n",
    "    leftClick()\n",
    "    # print \"===========================\\n\"\n",
    "    # print('Game restarted ')\n",
    "    # print \"===========================\\n\"\n",
    "\n",
    "def pauseGame():\n",
    "    \"\"\"\n",
    "        click pause/play game \n",
    "    \"\"\"\n",
    "    x,y = 7, 345\n",
    "    mousePos((x, y))\n",
    "    time.sleep(.1)\n",
    "    leftClick()\n",
    "    # print \"===========================\\n\"\n",
    "    # print('Game restarted ')\n",
    "    # print \"===========================\\n\"\n",
    "    \n",
    "\n",
    "def screenGrab():\n",
    "    x_pad = 1300\n",
    "    y_pad = 380\n",
    "    x=1536\n",
    "    y=690\n",
    "    box = (x_pad+1, y_pad+1, x, y)\n",
    "    im = ImageGrab.grab(box)\n",
    "    return im\n",
    "\n",
    "def leftClick():\n",
    "    win32api.mouse_event(win32con.MOUSEEVENTF_LEFTDOWN,0,0)\n",
    "    time.sleep(.1)\n",
    "    win32api.mouse_event(win32con.MOUSEEVENTF_LEFTUP,0,0)\n",
    "    # print \"left Click.\"\n",
    "\n",
    "def rightClick():\n",
    "    win32api.mouse_event(win32con.MOUSEEVENTF_RIGHTDOWN,0,0)\n",
    "    time.sleep(.1)\n",
    "    win32api.mouse_event(win32con.MOUSEEVENTF_RIGHTUP,0,0)\n",
    "    # print \"left Click.\"\n",
    "    \n",
    "def leftDown():\n",
    "    win32api.mouse_event(win32con.MOUSEEVENTF_LEFTDOWN,0,0)\n",
    "    time.sleep(.1)\n",
    "    # print 'left Down'\n",
    "         \n",
    "def leftUp():\n",
    "    win32api.mouse_event(win32con.MOUSEEVENTF_LEFTUP,0,0)\n",
    "    time.sleep(.1)\n",
    "    # print 'left release'\n",
    "\n",
    "# def mousePos(cord):\n",
    "#     win32api.SetCursorPos((x_pad + cord[0], y_pad + cord[1])\n",
    "\n",
    "def swipeDown():\n",
    "    x,y= -82, 554\n",
    "    x1,y1 = -82,600\n",
    "    mousePos((x,y))\n",
    "    win32api.mouse_event(win32con.MOUSEEVENTF_LEFTDOWN,0,0)\n",
    "    time.sleep(.1)\n",
    "    mousePos((x1,y1))\n",
    "    win32api.mouse_event(win32con.MOUSEEVENTF_LEFTUP,0,0)\n",
    "    # print 'swipe down complete'\n",
    "\n",
    "def swipeUp():\n",
    "    x1,y1= -82, 554\n",
    "    x,y = -82,600\n",
    "    mousePos((x,y))\n",
    "    win32api.mouse_event(win32con.MOUSEEVENTF_LEFTDOWN,0,0)\n",
    "    time.sleep(.1)\n",
    "    mousePos((x1,y1))\n",
    "    win32api.mouse_event(win32con.MOUSEEVENTF_LEFTUP,0,0)\n",
    "    # print 'swipe up complete'\n",
    "\n",
    "def swipeRight():\n",
    "    x,y= -82, 554\n",
    "    x1,y1= 0,554\n",
    "    mousePos((x,y))\n",
    "    win32api.mouse_event(win32con.MOUSEEVENTF_LEFTDOWN,0,0)\n",
    "    time.sleep(.1)\n",
    "    mousePos((x1,y1))\n",
    "    win32api.mouse_event(win32con.MOUSEEVENTF_LEFTUP,0,0)\n",
    "    # print 'swipe right complete'\n",
    "\n",
    "def swipeLeft():\n",
    "    x1,y1= -82, 554\n",
    "    x,y= 0,554\n",
    "    mousePos((x,y))\n",
    "    win32api.mouse_event(win32con.MOUSEEVENTF_LEFTDOWN,0,0)\n",
    "    time.sleep(.1)\n",
    "    mousePos((x1,y1))\n",
    "    win32api.mouse_event(win32con.MOUSEEVENTF_LEFTUP,0,0)\n",
    "    # print 'swipe left complete'\n",
    "\n",
    "def mousePos(cord):\n",
    "    win32api.SetCursorPos((x_pad + cord[0], y_pad + cord[1]))\n",
    "\n",
    "def get_cords():\n",
    "    x,y = win32api.GetCursorPos()\n",
    "    print (x,y)\n",
    "    x = x - x_pad\n",
    "    y = y - y_pad\n",
    "    print (x,y)\n",
    "\n",
    "def take_action(action):\n",
    "    \"\"\" executes action action. \"\"\"\n",
    "    if action == 0:\n",
    "        swipeUp()\n",
    "    elif action == 1:\n",
    "        swipeDown()            \n",
    "    elif action == 2:\n",
    "        swipeLeft()\n",
    "    elif action == 3:\n",
    "        swipeRight()\n",
    "    elif action == 4:\n",
    "        pass\n",
    "    else:\n",
    "        print('Unrecognized action %d' % action)\n",
    "\n",
    "def reset():\n",
    "    \"\"\" Repeats NO-OP action until a new episode begins. \"\"\"\n",
    "    restartGame()\n",
    "    time.sleep(.5)\n",
    "    state = screenGrab()\n",
    "    pauseGame()# pause play\n",
    "    return state\n",
    "\n",
    "def step(action, score):\n",
    "    status = checkGameOver()\n",
    "    # print status\n",
    "    s = getScore()\n",
    "    if status:\n",
    "        reward=0\n",
    "        s= score\n",
    "    else:\n",
    "        if s>score:\n",
    "            reward = 1000\n",
    "        else:\n",
    "            reward=-250\n",
    "        pauseGame()# restart play\n",
    "        take_action(action)\n",
    "        time.sleep(0.2)\n",
    "        \n",
    "        \n",
    "        s = getScore()  \n",
    "        if s==-1:\n",
    "            s=score\n",
    "        if status:\n",
    "            reward=0\n",
    "            s= score\n",
    "        else:\n",
    "            if s>score:\n",
    "                reward = 1000\n",
    "            else:\n",
    "                reward=-250\n",
    "    state = screenGrab()\n",
    "    episode_over = status\n",
    "    time.sleep(0.2)\n",
    "    pauseGame() # pause play\n",
    "    return state, reward, episode_over,s, {}    \n",
    "\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    # initialize environment and the agent\n",
    "    agent = DQNAgent()\n",
    "    episodes = 1200\n",
    "\n",
    "    # Iterate the game\n",
    "    for e in range(episodes):\n",
    "\n",
    "        # reset state in the beginning of each game\n",
    "        state = reset()\n",
    "        state = preprocess(state)\n",
    "        score = 0\n",
    "        # time_t represents each frame of the game\n",
    "        # Our goal is to keep the pole upright as long as possible\n",
    "        # the more time_t the more score\n",
    "        for time_t in range(5000):\n",
    "            # turn this on if you want to render\n",
    "            # env.roender()\n",
    "\n",
    "            # Decide action\n",
    "            action = agent.act(state)\n",
    "            \n",
    "            # Advance the game to the next frame based on the action.\n",
    "            next_state, reward, done,score, _ = step(action, score)\n",
    "            next_state = preprocess(next_state)\n",
    "\n",
    "            # (reward defaults to 1)\n",
    "            # reward the agent 1 for every frame it lived\n",
    "            # and punish -100 for dying\n",
    "            reward = -5000 if done else reward\n",
    "\n",
    "            # Remember the previous state, action, reward, and done\n",
    "            agent.remember(state, action, reward, next_state, done)\n",
    "\n",
    "            # make next_state the new current state for the next frame.\n",
    "            state = copy.deepcopy(next_state)\n",
    "\n",
    "            # done becomes True when the game ends\n",
    "            # ex) The agent drops the pole\n",
    "            if done:\n",
    "                # print the score and break out of the loop\n",
    "                print(\"episode: {}/{}, score: {}\"\n",
    "                      .format(e, episodes, score))\n",
    "                break\n",
    "        # train the agent with the experience of the episode\n",
    "        agent.replay(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
